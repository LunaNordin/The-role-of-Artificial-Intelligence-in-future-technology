\documentclass[a4paper, conference]{IEEEtran}

\input epsf

\usepackage{graphicx}

\usepackage[
    backend=biber,
    style=numeric,
    sorting = none,
    natbib=true,
    url=false, 
    doi=false,
    eprint=false
]{biblatex}
\addbibresource{cites.bib}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    citecolor = blue,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    pdftitle={Overleaf Example},
    }


\begin{document}

\title{\LARGE The role of Artificial Intelligence in future technology}

\author{\authorblockN{Frederik Schittny} \\ May 2024 \\ \small Submitted as part of an application for the Computer Science (M.Sc.) program \\ at the Technical University of Munich}

\maketitle


\IEEEoverridecommandlockouts
\IEEEpeerreviewmaketitle

\section{Introduction}
Since Artificial Intelligence (AI) is most broadly defined as intelligence exerted by computers or other artificial machines \cite[p. 29]{aiModernApproach}, the classification of what is an AI system and what is not heavily depends on the underlying definition of intelligence \cite[p. 31]{aiModernApproach}. Because AI is a field of research in computer science rather than a specific technology \cite[p. 1]{aiStructuresStrategies}, it includes a variety of subfields like learning, reasoning, knowledge representation, and data analysis \cite[pp. 20-30]{aiStructuresStrategies}.\\

The introduction of AI as a computer science research field took place in 1956 during the Dartmouth Summer Research Project on Artificial Intelligence \cite{dartmouthFiftyYears}. However, theoretical considerations of artificial and machine-based intelligence date back earlier, for example, in philosophy \cite[pp. 5-6]{Flasiński2016} or science fiction \cite[pp. 29-40]{riseOfSelfReplicators}. Notable early forms of AI research predating the Dartmouth Research Project include Turing's considerations on machine-based intelligence \cite{Turing1950ComputingMA}, as well as McCulloch and Pitts introduction of artificial neurons as mathematical structures \cite{mcculloch43a}.\\

The development of AI over the following decades up to today was not characterized by continuous progress, but rather by alternating phases of so-called AI booms and AI winters \cite{AiWinterLessons, briefHistory}. The AI booms were phases of consecutive research breakthroughs like the 1960s, in which research focused on the first uses of neural networks and language processing \cite[pp. 65-69]{aiModernApproach} or the AI boom from 1980 to 1987 with the widespread use of expert systems \cite[pp. 71-74]{aiModernApproach}. More modern phases of AI boom include the years between 2000 and 2011 in which AI was widely incorporated into consumer applications by big technology companies \cite{voiceAssistants}, as well as the 2010s in which the main focus of AI development was on deep learning and commercial big data analysis \cite[pp. 77-79, p.5]{aiModernApproach, briefHistory}. The phases in between, often referred to as AI winters, were periods of reduced academic progress, frequently accompanied or initiated by a lack of funding, insufficient computational power, and a lack of public interest \cite{AiWinterLessons, aiModernApproach}. The exact classification varies, but the phases from 1974 to 1980 and 1987 to 2000 are often considered the two major AI winters \cite{Toosi_2021, aiModernApproach}.\\

Today, AI systems are used in various fields including finance \cite[p. 1845]{aiModernApproach}, medical applications \cite[p. 84]{aiModernApproach}, manufacturing \cite[p. 293]{aiStructuresStrategies}, gaming \cite[pp. 45-46]{aiStructuresStrategies}, logistics \cite[pp. 82-83]{aiModernApproach} and military applications \cite[pp. 86, 1031]{aiModernApproach}. Despite the widespread use of AI in consumer applications like text autocompletion and correction, voice assistants, or search and recommendation algorithms, and their importance in the everyday life of many people, these systems are often not recognized or perceived as AI applications \cite{studyAIusage}.\\

\section{Recent advancements}
The last boost of AI development was mainly driven by AI models based on the transformer architecture introduced in 2017 \cite{transformer}. Especially the introduction of GPT-3 by OpenAI in 2020 \cite{brown2020language} marked the beginning of a variety of different tools like chatbots \cite{googleGemini, openAiChatGPT}, AI-powered search engines \cite{perplexity} as well as tools generating audiovisual materials based on text prompts \cite{midjourney, dalle}. Transformer-based AI models were quickly incorporated into numerous consumer software products and saw rapid adoption by end users \cite[pp. 437-451]{AiIndexReport24}. This advancement marks the milestone of AI models being able to mass generate texts and audiovisual content, which is difficult to recognize as non-human generated by most people \cite{frank2023representative}. The extreme popularity of these tools makes this milestone comparable to other AI milestones with high media attention, like the chess AI Deep Blue beating world chess champion Garry Kasparov in 1997. In contrast to other consumer software products mentioned above, the new transformer-based models are highly recognized as AI technology by most consumers \cite[pp. 33-37]{littman2022gathering}.\\

\section{Current problems and near-future development}
The quickly advancing development of AI applications has highlighted several technical and societal problems. Solving these problems is the current effort of a variety of companies and research institutions. Since partial solutions and solution approaches are foreseeable or already under discussion, a look at current problems allows for a prediction of the near-future development of AI.\\

Technical problems include the reliability and explainability of AI models' outputs, as current models can experience so-called hallucinations \cite{huang2023survey} and struggle with logic and temporal coherence of information \cite{chen2023learning}. Solving this problem, ideally by making the models' processes comprehensible \cite[pp. 1312-1315]{aiModernApproach}, would allow for AI models to be used in more critical and high-risk scenarios. Another technical problem is the high energy demand of training processes, which poses a potential risk for efforts toward climate protection \cite{Dhar2020}. Smaller, more efficient models could not only alleviate the concerns about the climate impact of AI but would also allow on-device usage with less powerful hardware, often referred to as edge computing \cite{AiEdge}, making AI applications more accessible and easier to adapt in many situations.\\

Besides technical problems, there are also highly discussed societal concerns with current AI developments. This includes algorithmic biases discriminating against certain groups, mostly caused by biased training data \cite[pp. 1812-1818]{aiModernApproach}. Other concerns are copyright \cite{genAiCopyright} and privacy issues \cite[pp. 1807-1812]{aiModernApproach} caused by the mass data collection necessary for the training of large AI models, as well as misinformation issues \cite[p. 55]{littman2022gathering} caused by the new ability of AI models to produce realistic media content. While these problems do not directly impede the further adoption and development of current AI technology, they undermine the trust and reputation of AI as a technology in the view of many users. Therefore, specialized regulation and law enforcement, as well as industry standards, are necessary to prevent a potential future backlash against AI.\\

\section{From multimodal AI to AGI}
The long-term development goal stated by many companies and researchers is Artificial General Intelligence (AGI) \cite{openAiAgi, googleDeepMindAgi}. The definition is once again dependent on the conception of the term intelligence, but is generally understood to describe a system possessing human-like intelligence rather than just imitating it \cite[pp. 88-89]{aiModernApproach}.\\

One approach to AGI is training increasingly large and capable multimodal models \cite{Fei2022}. These can not only process and output one form of data like text but several different ones, including audiovisual information and the ability to perform actions in digital or even real-world environments \cite{baltrušaitis2017multimodal}. While multimodality is a recent concept and can be designated a near-future development, there are not only discussions about whether current models show first features of AGI \cite[pp. 92-95]{bubeck2023sparks} but also doubt from experts whether these models understand their outputs in a human-like way \cite{mahowald2024dissociating}.\\

If AGI can match or surpass human intelligence, this new technology will present both new benefits and challenges. AGI could prove to be more reliable, versatile and capable than current AI models and could potentially take over many tasks performed by humans today, yielding improved productivity and efficiency in many areas. On the other hand, it would drastically amplify existing concerns like job displacement \cite[p. 1821-1826]{aiModernApproach} and the potential for weaponization \cite[1803-1807]{aiModernApproach} and could pose an existential threat to humanity \cite{Turchin2020-TURCOG-2}. These issues become especially concerning in the case of self-improving systems \cite[pp. 1832-1833]{aiModernApproach}.\\

Estimations of when AGI will be achieved vary widely \cite{scienceAgiDiscussion, zhang2022forecasting, Fjelland2020}. This is partly due to the vague definition of AGI and the lack of expressive tests. Early tests for identifying intelligent machines, like the Turing test, were arguably passed by programs not falling under the AGI definition \cite[p. 1796]{aiModernApproach}. The original approach of modelling human neurons has not proven effective in producing intelligence yet, but is further pursued through research on whole-brain simulation \cite{Stiefel2019}. However, this and other approaches are still constrained by technical limits like computational power and availability of training data \cite[pp. 681-703]{aiStructuresStrategies}. Besides this, the inadequate understanding of intelligence itself makes developing approaches to AGI difficult \cite[pp. 24-29]{littman2022gathering}.\\

\section{Conclusion}
The near-future development of AI can be predicted with relative certainty based on research and first approaches to current problems. These point towards AI being further adopted into everyday life and taking over more tasks as availability and reliability improve. This progress could be slowed down either by missing regulations and unsolved societal problems impacting the reputation and acceptance of AI or by consequent overregulation.\\

The long-term goal of AGI is already specified; however, a clear definition, working approaches, and standardized testing methods do not yet exist. Up until now, the development of AI has been characterized by alternating phases of AI booms and AI winters, and it is unlikely the current boom phase will continue indefinitely.\\

\printbibliography

\end{document}